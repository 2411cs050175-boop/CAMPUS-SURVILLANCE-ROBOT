import pandas as pd
import numpy as np
import cv2
import os
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from tqdm import tqdm  # progress bar

# === CONFIG ===
IMG_SIZE = 128  # resize images to 128x128
DATA_CSV = "student_labels.csv"  # CSV file path

# === STEP 1: Load CSV ===
df = pd.read_csv(DATA_CSV)
print(f"ðŸ“„ Loaded CSV with {len(df)} rows")

# Determine base directory for relative image paths
BASE_DIR = os.path.dirname(os.path.abspath(DATA_CSV))

# === STEP 2: Read images and labels ===
images = []
id_labels = []
inshirt_labels = []

print("ðŸ“· Reading images...")

for _, row in tqdm(df.iterrows(), total=len(df), desc="Loading images"):
    img_path = row["image_path"]

    # Make image path absolute
    if not os.path.isabs(img_path):
        img_path = os.path.join(BASE_DIR, img_path)

    # Check if file exists
    if not os.path.exists(img_path):
        print(f"âš  File not found: {img_path}")
        continue

    # Read image safely
    img = cv2.imread(img_path)
    if img is None:
        print(f"âš  Could not read image: {img_path}")
        continue

    # Convert and resize
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))

    images.append(img)
    id_labels.append(row["id_card"])
    inshirt_labels.append(row["inshirt"])

# Convert to numpy arrays
X = np.array(images, dtype="float32") / 255.0
y_id = np.array(id_labels, dtype="float32")
y_in = np.array(inshirt_labels, dtype="float32")

print(f"âœ… Data prepared: {X.shape[0]} valid images of size {IMG_SIZE}x{IMG_SIZE}")

# === STEP 3: Split into train and test ===
X_train, X_test, y_id_train, y_id_test, y_in_train, y_in_test = train_test_split(
    X, y_id, y_in, test_size=0.2, random_state=42
)

print(f"ðŸ§© Train size: {X_train.shape[0]} | Test size: {X_test.shape[0]}")

# === STEP 4: Define CNN model ===
input_layer = Input(shape=(IMG_SIZE, IMG_SIZE, 3))

x = Conv2D(32, (3, 3), activation='relu')(input_layer)
x = MaxPooling2D(2, 2)(x)
x = Conv2D(64, (3, 3), activation='relu')(x)
x = MaxPooling2D(2, 2)(x)
x = Conv2D(128, (3, 3), activation='relu')(x)
x = MaxPooling2D(2, 2)(x)
x = Flatten()(x)
x = Dropout(0.4)(x)

# Two output branches
id_output = Dense(1, activation='sigmoid', name='id_card')(x)
inshirt_output = Dense(1, activation='sigmoid', name='inshirt')(x)

model = Model(inputs=input_layer, outputs=[id_output, inshirt_output])

# === STEP 5: Compile model ===
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss={'id_card': 'binary_crossentropy', 'inshirt': 'binary_crossentropy'},
    metrics={'id_card': 'accuracy', 'inshirt': 'accuracy'}
)

model.summary()

# === STEP 6: Train model ===
history = model.fit(
    X_train,
    {'id_card': y_id_train, 'inshirt': y_in_train},
    validation_data=(X_test, {'id_card': y_id_test, 'inshirt': y_in_test}),
    epochs=10,
    batch_size=16
)

# === STEP 7: Save model ===
model.save("student_cnn_model.h5")
print("âœ… Model saved as 'student_cnn_model.h5'")